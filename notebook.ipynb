{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Structure cr√©√©e\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports des biblioth√®ques n√©cessaires\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "import scipy.sparse as sp\n",
    "\n",
    "# Cr√©ation directories\n",
    "DATA_DIR = Path(\"data\")\n",
    "MODEL_DIR = Path(\"models\")\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "\n",
    "for directory in [DATA_DIR / \"raw\", \n",
    "                  DATA_DIR / \"processed\", \n",
    "                  DATA_DIR / \"relish\",\n",
    "                  MODEL_DIR, \n",
    "                  RESULTS_DIR]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úì Structure cr√©√©e\")\n",
    "\n",
    "# Hyperparam√®tres globaux du projet :\n",
    "# - TFIDF_MAX_FEATURES : taille maximale du vocabulaire TF-IDF\n",
    "# - W2V_DIM : dimension des vecteurs Word2Vec\n",
    "# - W2V_WINDOW : taille de la fen√™tre contextuelle Word2Vec\n",
    "# - ALPHA_TFIDF / BETA_W2V : pond√©rations pour la fusion TF-IDF + Word2Vec\n",
    "# - TOP_K : nombre de documents retourn√©s lors du retrievalTFIDF_MAX_FEATURES = 50000\n",
    "W2V_DIM = 200\n",
    "W2V_WINDOW = 5\n",
    "ALPHA_TFIDF = 0.6\n",
    "BETA_W2V = 0.4\n",
    "TOP_K = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Fichier 1 : Corpus (163K documents)   \n",
    "wget https://zenodo.org/records/14801641/files/relish_documents.tsv  \n",
    "\n",
    "Contient ~163 000 documents scientifiques.  \n",
    "Chaque entr√©e correspond √† un article (texte, identifiant, m√©tadonn√©es) qui constitue l‚Äôespace de recherche du syst√®me de retrieval.\n",
    " \n",
    "Fichier 2 : Ground truth (189K paires)    \n",
    "wget https://zenodo.org/records/14801641/files/relevance_matrix.tsv\n",
    "\n",
    "Ce fichier sert de r√©f√©rence d‚Äô√©valuation (gold standard) pour mesurer la qualit√© du syst√®me de retrieval (pr√©cision, rappel, ranking).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì relish_documents.tsv trouv√© (264.6 MB)\n",
      "‚úì relevance_matrix.tsv trouv√© (4.5 MB)\n"
     ]
    }
   ],
   "source": [
    "# Ce bloc sert √† s√©curiser le chargement des donn√©es RELISH avant toute analyse.\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RELISH_DIR = DATA_DIR / \"relish\"\n",
    "\n",
    "# Cr√©ation structure\n",
    "RELISH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# V√©rification pr√©sence fichiers\n",
    "corpus_file = RELISH_DIR / \"relish_documents.tsv\"\n",
    "qrels_file = RELISH_DIR / \"relevance_matrix.tsv\"\n",
    "\n",
    "if corpus_file.exists():\n",
    "    size_mb = corpus_file.stat().st_size / (1024**2)\n",
    "    print(f\"‚úì relish_documents.tsv trouv√© ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"    relish_documents.tsv manquant\")\n",
    "    print(f\"   T√©l√©charge depuis : https://zenodo.org/records/14801641\")\n",
    "    print(f\"   Place dans : {corpus_file}\")\n",
    "\n",
    "if qrels_file.exists():\n",
    "    size_mb = qrels_file.stat().st_size / (1024**2)\n",
    "    print(f\"‚úì relevance_matrix.tsv trouv√© ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"   relevance_matrix.tsv manquant\")\n",
    "    print(f\"   T√©l√©charge depuis : https://zenodo.org/records/14801641\")\n",
    "    print(f\"   Place dans : {qrels_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement corpus...\n",
      "‚úì Corpus : 163189 documents\n",
      "Colonnes : ['PMID', 'title', 'abstract']\n",
      "Apr√®s nettoyage : 163189 documents\n",
      "\n",
      "Exemple :\n",
      "pmid                                              24013020\n",
      "title    Potentially harmful elements (PHEs) in scalp h...\n",
      "Name: 0, dtype: object\n",
      "Abstract (100 chars) : Internationally publicized impacts upon human health associated with potentially harmful element (PH...\n",
      "\n",
      "Chargement ground truth...\n",
      "‚úì Qrels : 189634 paires\n",
      "Colonnes : ['PMID1', 'PMID2', 'Relevance', 'Cosine Similarity']\n",
      "\n",
      "Distribution scores relevance :\n",
      "relevance\n",
      "0    55749\n",
      "1    65406\n",
      "2    68479\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cr√©ation mapping query‚Üídocuments pertinents...\n",
      "‚úì 3190 queries uniques\n",
      "Moyenne docs pertinents/query : 42.0\n",
      "Min : 1, Max : 60\n",
      "\n",
      "‚úì Donn√©es pr√©par√©es sauvegard√©es dans data/processed\n"
     ]
    }
   ],
   "source": [
    "# pr√©-traitement complet de RELISH : chargement, nettoyage, structuration\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "RELISH_DIR = DATA_DIR / \"relish\"\n",
    "\n",
    "# V√©rification fichiers\n",
    "corpus_file = RELISH_DIR / \"relish_documents.tsv\"\n",
    "qrels_file = RELISH_DIR / \"relevance_matrix.tsv\"\n",
    "\n",
    "if not corpus_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing file : {corpus_file}\\n\"\n",
    "        \"Download from https://zenodo.org/records/14801641\\n\"\n",
    "        \"Place in data/relish/\"\n",
    "    )\n",
    "\n",
    "if not qrels_file.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Missing file  : {qrels_file}\\n\"\n",
    "        \"Download from https://zenodo.org/records/14801641\\n\"\n",
    "        \"Place in data/relish/\"\n",
    "    )\n",
    "\n",
    "# CHARGEMENT CORPUS\n",
    "\n",
    "print(\"Chargement corpus...\")\n",
    "corpus_df = pd.read_csv(corpus_file, sep='\\t')\n",
    "\n",
    "# Inspection structure\n",
    "print(f\"‚úì Corpus : {len(corpus_df)} documents\")\n",
    "print(f\"Colonnes : {corpus_df.columns.tolist()}\")\n",
    "\n",
    "# Standardisation noms colonnes si n√©cessaire\n",
    "if 'PMID' in corpus_df.columns:\n",
    "    corpus_df.rename(columns={'PMID': 'pmid', 'Title': 'title', 'Abstract': 'abstract'}, \n",
    "                     inplace=True)\n",
    "\n",
    "# Nettoyage\n",
    "corpus_df = corpus_df.dropna(subset=['abstract'])  # Supprime docs sans abstract\n",
    "corpus_df['pmid'] = corpus_df['pmid'].astype(str)\n",
    "\n",
    "print(f\"Apr√®s nettoyage : {len(corpus_df)} documents\")\n",
    "print(f\"\\nExemple :\")\n",
    "print(corpus_df.iloc[0][['pmid', 'title']])\n",
    "print(f\"Abstract (100 chars) : {corpus_df.iloc[0]['abstract'][:100]}...\")\n",
    "\n",
    "# CHARGEMENT QRELS\n",
    "\n",
    "\n",
    "print(\"\\nChargement ground truth...\")\n",
    "qrels_df = pd.read_csv(qrels_file, sep='\\t')\n",
    "\n",
    "print(f\"‚úì Qrels : {len(qrels_df)} paires\")\n",
    "print(f\"Colonnes : {qrels_df.columns.tolist()}\")\n",
    "\n",
    "# Standardisation\n",
    "if 'PMID1' in qrels_df.columns:\n",
    "    qrels_df.rename(columns={'PMID1': 'pmid1', 'PMID2': 'pmid2', 'Relevance': 'relevance'}, \n",
    "                    inplace=True)\n",
    "\n",
    "qrels_df['pmid1'] = qrels_df['pmid1'].astype(str)\n",
    "qrels_df['pmid2'] = qrels_df['pmid2'].astype(str)\n",
    "\n",
    "# Distribution relevance\n",
    "print(\"\\nDistribution scores relevance :\")\n",
    "print(qrels_df['relevance'].value_counts().sort_index())\n",
    "\"\"\"\n",
    "Attendu :\n",
    "0 (irrelevant) : ~55K paires\n",
    "1 (partially relevant) : ~65K paires\n",
    "2 (completely relevant) : ~68K paires\n",
    "\"\"\"\n",
    "\n",
    "# ============================================\n",
    "# CR√âATION MAPPING QUERY -> RELEVANT DOCS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nCr√©ation mapping query‚Üídocuments pertinents...\")\n",
    "\n",
    "query_relevant = {}\n",
    "for _, row in qrels_df.iterrows():\n",
    "    query_pmid = row['pmid1']\n",
    "    doc_pmid = row['pmid2']\n",
    "    relevance = row['relevance']\n",
    "    \n",
    "    if query_pmid not in query_relevant:\n",
    "        query_relevant[query_pmid] = {'relevant': [], 'irrelevant': []}\n",
    "    \n",
    "    if relevance > 0:  # Partially ou completely relevant\n",
    "        query_relevant[query_pmid]['relevant'].append({\n",
    "            'pmid': doc_pmid,\n",
    "            'score': relevance\n",
    "        })\n",
    "    else:\n",
    "        query_relevant[query_pmid]['irrelevant'].append(doc_pmid)\n",
    "\n",
    "print(f\"‚úì {len(query_relevant)} queries uniques\")\n",
    "\n",
    "# Statistiques\n",
    "n_relevant = [len(v['relevant']) for v in query_relevant.values()]\n",
    "print(f\"Moyenne docs pertinents/query : {np.mean(n_relevant):.1f}\")\n",
    "print(f\"Min : {np.min(n_relevant)}, Max : {np.max(n_relevant)}\")\n",
    "\n",
    "# SAUVEGARDE FORMAT PICKLE\n",
    "\n",
    "processed_dir = DATA_DIR / \"processed\"\n",
    "processed_dir.mkdir(exist_ok=True)\n",
    "\n",
    "corpus_df.to_pickle(processed_dir / \"corpus.pkl\")\n",
    "\n",
    "import pickle\n",
    "with open(processed_dir / \"query_relevant.pkl\", 'wb') as f:\n",
    "    pickle.dump(query_relevant, f)\n",
    "\n",
    "print(f\"\\n‚úì Donn√©es pr√©par√©es sauvegard√©es dans {processed_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing abstracts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/163189 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 163189/163189 [02:01<00:00, 1345.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Preprocessing termin√©\n",
      "Longueur moyenne : 138 tokens\n",
      "Min : 3, Max : 1515\n",
      "\n",
      "Apr√®s filtrage (‚â•20 tokens) : 162863 documents\n",
      "‚úì Corpus preprocessed sauvegard√©\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Configuration tqdm pour pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# T√©l√©chargements NLTK\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenization + lemmatization + stopword removal\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # Lowercase + suppression ponctuation/chiffres\n",
    "    text = re.sub(r'[^a-z\\s]', '', text.lower())\n",
    "    \n",
    "    # Tokenization\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Lemmatization + stopwords + longueur minimale\n",
    "    tokens = [lemmatizer.lemmatize(t) for t in tokens \n",
    "              if t not in stop_words and len(t) > 2]\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Application corpus avec progress bar\n",
    "print(\"Preprocessing abstracts...\")\n",
    "corpus_df['tokens'] = corpus_df['abstract'].progress_apply(preprocess_text)\n",
    "corpus_df['text_clean'] = corpus_df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Statistiques\n",
    "lengths = corpus_df['tokens'].apply(len)\n",
    "print(f\"\\n‚úì Preprocessing termin√©\")\n",
    "print(f\"Longueur moyenne : {lengths.mean():.0f} tokens\")\n",
    "print(f\"Min : {lengths.min()}, Max : {lengths.max()}\")\n",
    "\n",
    "# Filtrage documents trop courts\n",
    "min_length = 20\n",
    "corpus_df = corpus_df[corpus_df['tokens'].apply(len) >= min_length]\n",
    "print(f\"\\nApr√®s filtrage (‚â•{min_length} tokens) : {len(corpus_df)} documents\")\n",
    "\n",
    "# Sauvegarde\n",
    "corpus_df.to_pickle(DATA_DIR / \"processed/corpus_preprocessed.pkl\")\n",
    "print(\"‚úì Corpus preprocessed sauvegard√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entra√Ænement TF-IDF...\n",
      "\n",
      "‚úì TF-IDF shape : (162863, 50000)\n",
      "Sparsity : 0.0023\n",
      "Vocabulaire : 50000 termes\n",
      "\n",
      "Top 20 termes IDF (rares/sp√©cifiques) :\n",
      "  oxt : 10.52\n",
      "  hfmd : 10.52\n",
      "  cisnats : 10.52\n",
      "  alri : 10.52\n",
      "  townsend : 10.52\n",
      "  desferrioxamine : 10.52\n",
      "  ucmscs : 10.52\n",
      "  rtw : 10.52\n",
      "  ffdm : 10.60\n",
      "  apremilast : 10.60\n",
      "  rfsh : 10.60\n",
      "  fma : 10.70\n",
      "  rsph : 10.70\n",
      "  vmws : 10.70\n",
      "  usuv : 10.80\n",
      "  deferiprone : 10.80\n",
      "  neph : 10.80\n",
      "  irisin : 11.05\n",
      "  tachinidae : 11.05\n",
      "  icps : 11.21\n",
      "\n",
      "‚úì Mod√®les sauvegard√©s dans models\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "\n",
    "print(\"Entra√Ænement TF-IDF...\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=50000,      # Top 50K termes\n",
    "    ngram_range=(1, 2),      # Unigrams + bigrams\n",
    "    min_df=5,                # Ignore termes <5 docs\n",
    "    max_df=0.8,              # Ignore termes >80% docs\n",
    "    sublinear_tf=True        # Log scaling TF\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(corpus_df['text_clean'])\n",
    "\n",
    "print(f\"\\n‚úì TF-IDF shape : {tfidf_matrix.shape}\")\n",
    "print(f\"Sparsity : {tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]):.4f}\")\n",
    "print(f\"Vocabulaire : {len(vectorizer.vocabulary_)} termes\")\n",
    "\n",
    "# Top termes par IDF\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "idfs = vectorizer.idf_\n",
    "top_idfs = np.argsort(idfs)[-20:]\n",
    "print(f\"\\nTop 20 termes IDF (rares/sp√©cifiques) :\")\n",
    "for idx in top_idfs:\n",
    "    print(f\"  {feature_names[idx]} : {idfs[idx]:.2f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "pickle.dump(vectorizer, open(MODEL_DIR / \"tfidf_vectorizer.pkl\", \"wb\"))\n",
    "sp.save_npz(MODEL_DIR / \"tfidf_matrix.npz\", tfidf_matrix)\n",
    "print(f\"\\n‚úì Mod√®les sauvegard√©s dans {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entra√Ænement Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entra√Ænement Word2Vec...\n",
      "Corpus : 162863 documents\n",
      "\n",
      "‚úì Entra√Ænement termin√©\n",
      "Vocabulaire : 56557 termes\n",
      "\n",
      "Exemples similarit√©s :\n",
      "\n",
      "cancer :\n",
      "  colorectal : 0.728\n",
      "  breast : 0.725\n",
      "  crc : 0.684\n",
      "  carcinoma : 0.677\n",
      "  adenocarcinoma : 0.676\n",
      "\n",
      "tumor :\n",
      "  tumour : 0.891\n",
      "  metastasis : 0.672\n",
      "  tumoral : 0.634\n",
      "  xenograft : 0.624\n",
      "  glioma : 0.620\n",
      "\n",
      "treatment :\n",
      "  therapy : 0.694\n",
      "  treating : 0.693\n",
      "  treated : 0.650\n",
      "  treat : 0.582\n",
      "  polychemotherapy : 0.554\n",
      "\n",
      "patient :\n",
      "  enrolled : 0.628\n",
      "  dialysisdependent : 0.618\n",
      "  diagnosed : 0.613\n",
      "  electively : 0.612\n",
      "  subject : 0.584\n",
      "\n",
      "cell :\n",
      "  proliferation : 0.654\n",
      "  cdpos : 0.643\n",
      "  aldhpositive : 0.627\n",
      "  mdambs : 0.602\n",
      "  bmecs : 0.602\n",
      "\n",
      "‚úì Word2Vec sauvegard√© dans models\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "print(\"Entra√Ænement Word2Vec...\")\n",
    "print(f\"Corpus : {len(corpus_df)} documents\")\n",
    "\n",
    "sentences = corpus_df['tokens'].tolist()\n",
    "\n",
    "# Hyperparam√®tres\n",
    "W2V_DIM = 200\n",
    "W2V_WINDOW = 5\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=W2V_DIM,\n",
    "    window=W2V_WINDOW,\n",
    "    min_count=W2V_MIN_COUNT,\n",
    "    workers=4,\n",
    "    epochs=10,\n",
    "    sg=1,              # Skip-gram (meilleur que CBOW pour petit corpus)\n",
    "    negative=5,        # Negative sampling\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì Entra√Ænement termin√©\")\n",
    "print(f\"Vocabulaire : {len(w2v_model.wv)} termes\")\n",
    "\n",
    "# Tests similarit√©s\n",
    "test_terms = ['cancer', 'tumor', 'treatment', 'patient', 'cell']\n",
    "print(\"\\nExemples similarit√©s :\")\n",
    "for term in test_terms:\n",
    "    if term in w2v_model.wv:\n",
    "        similar = w2v_model.wv.most_similar(term, topn=5)\n",
    "        print(f\"\\n{term} :\")\n",
    "        for word, score in similar:\n",
    "            print(f\"  {word} : {score:.3f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "w2v_model.save(str(MODEL_DIR / \"word2vec.model\"))\n",
    "print(f\"\\n‚úì Word2Vec sauvegard√© dans {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pr√©-calcul embeddings documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcul embeddings documents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162863/162863 [00:59<00:00, 2754.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Embeddings calcul√©s\n",
      "Documents avec embedding : 162863/162863 (100.0%)\n",
      "‚úì Sauvegard√© dans models/doc_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "print(\"Calcul embeddings documents...\")\n",
    "\n",
    "doc_embeddings = np.zeros((len(corpus_df), W2V_DIM))\n",
    "\n",
    "for i, tokens in tqdm(enumerate(corpus_df['tokens']), total=len(corpus_df)):\n",
    "    # Vecteurs termes pr√©sents dans vocabulaire\n",
    "    vecs = [w2v_model.wv[t] for t in tokens if t in w2v_model.wv]\n",
    "    \n",
    "    if vecs:\n",
    "        # Moyenne vecteurs\n",
    "        doc_embeddings[i] = np.mean(vecs, axis=0)\n",
    "    # Sinon reste vecteur z√©ro\n",
    "\n",
    "# Statistiques\n",
    "non_zero = np.count_nonzero(doc_embeddings.sum(axis=1))\n",
    "print(f\"\\n‚úì Embeddings calcul√©s\")\n",
    "print(f\"Documents avec embedding : {non_zero}/{len(corpus_df)} ({100*non_zero/len(corpus_df):.1f}%)\")\n",
    "\n",
    "# Sauvegarde\n",
    "np.save(MODEL_DIR / \"doc_embeddings.npy\", doc_embeddings)\n",
    "print(f\"‚úì Sauvegard√© dans {MODEL_DIR}/doc_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classe \n",
    "\n",
    "Cette cellule d√©finit et initialise le **retriever hybride**. Il combine TF-IDF et Word2Vec pour scorer les documents par similarit√© lexicale et s√©mantique, fusionne les scores, puis retourne les documents les plus pertinents pour une requ√™te donn√©e.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement mod√®les...\n",
      "‚úì Retriever initialis√©\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class HybridRetriever:\n",
    "    def __init__(self, corpus, tfidf_vec, tfidf_mat, w2v_model, doc_embs, alpha=0.6, beta=0.4):\n",
    "        self.corpus = corpus.reset_index(drop=True)\n",
    "        self.vectorizer = tfidf_vec\n",
    "        self.tfidf_matrix = tfidf_mat\n",
    "        self.w2v = w2v_model\n",
    "        self.doc_embeddings = doc_embs\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "    \n",
    "    def retrieve(self, query_text, top_k=10, return_scores=False):\n",
    "        \"\"\"Retrieval hybride TF-IDF + Word2Vec\"\"\"\n",
    "        \n",
    "        # Preprocessing query\n",
    "        query_tokens = preprocess_text(query_text)\n",
    "        query_clean = ' '.join(query_tokens)\n",
    "        \n",
    "        # TF-IDF scoring\n",
    "        query_vec_tfidf = self.vectorizer.transform([query_clean])\n",
    "        tfidf_scores = cosine_similarity(query_vec_tfidf, self.tfidf_matrix).flatten()\n",
    "        \n",
    "        # Word2Vec scoring\n",
    "        w2v_scores = self._compute_w2v_scores(query_tokens)\n",
    "        \n",
    "        # Normalisation [0,1] avant hybridation\n",
    "        tfidf_scores = (tfidf_scores - tfidf_scores.min()) / (tfidf_scores.max() - tfidf_scores.min() + 1e-10)\n",
    "        w2v_scores = (w2v_scores - w2v_scores.min()) / (w2v_scores.max() - w2v_scores.min() + 1e-10)\n",
    "        \n",
    "        # Hybridation\n",
    "        final_scores = self.alpha * tfidf_scores + self.beta * w2v_scores\n",
    "        \n",
    "        # Top-K\n",
    "        top_indices = np.argsort(final_scores)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            result = {\n",
    "                \"rank\": len(results) + 1,\n",
    "                \"pmid\": self.corpus.iloc[idx]['pmid'],\n",
    "                \"title\": self.corpus.iloc[idx]['title'],\n",
    "                \"score\": final_scores[idx],\n",
    "            }\n",
    "            if return_scores:\n",
    "                result[\"tfidf_score\"] = tfidf_scores[idx]\n",
    "                result[\"w2v_score\"] = w2v_scores[idx]\n",
    "            results.append(result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def _compute_w2v_scores(self, query_tokens):\n",
    "        \"\"\"Calcul similarit√© Word2Vec query-documents\"\"\"\n",
    "        # Embedding query\n",
    "        query_vecs = [self.w2v.wv[t] for t in query_tokens if t in self.w2v.wv]\n",
    "        \n",
    "        if not query_vecs:\n",
    "            return np.zeros(len(self.corpus))\n",
    "        \n",
    "        query_emb = np.mean(query_vecs, axis=0)\n",
    "        \n",
    "        # Similarit√© vectoris√©e avec tous documents\n",
    "        scores = cosine_similarity([query_emb], self.doc_embeddings)[0]\n",
    "        \n",
    "        return scores\n",
    "\n",
    "# Instanciation\n",
    "print(\"Chargement mod√®les...\")\n",
    "corpus_df = pd.read_pickle(DATA_DIR / \"processed/corpus_preprocessed.pkl\")\n",
    "vectorizer = pickle.load(open(MODEL_DIR / \"tfidf_vectorizer.pkl\", \"rb\"))\n",
    "tfidf_matrix = sp.load_npz(MODEL_DIR / \"tfidf_matrix.npz\")\n",
    "w2v_model = Word2Vec.load(str(MODEL_DIR / \"word2vec.model\"))\n",
    "doc_embeddings = np.load(MODEL_DIR / \"doc_embeddings.npy\")\n",
    "\n",
    "retriever = HybridRetriever(\n",
    "    corpus_df, vectorizer, tfidf_matrix, w2v_model, doc_embeddings,\n",
    "    alpha=0.6, beta=0.4\n",
    ")\n",
    "\n",
    "print(\"‚úì Retriever initialis√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query test (PMID 24013020) :\n",
      "Internationally publicized impacts upon human health associated with potentially harmful element (PHE) exposure have been reported amongst internally displaced populations (IDPs) in Mitrovica, Kosovo,\n",
      "\n",
      "================================================================================\n",
      "\n",
      "   rank      pmid                                              title  \\\n",
      "0     1  24013020  Potentially harmful elements (PHEs) in scalp h...   \n",
      "1     2  28558285  Enhancing the interpretation of in vitro bioac...   \n",
      "2     3  28162042  The Syrian public health and humanitarian cris...   \n",
      "3     4  21813430  Prevalence of war-related mental health condit...   \n",
      "4     5  27411086  Epidemiology of Substance Use among Forced Mig...   \n",
      "5     6  29747641  The Syrian conflict: a case study of the chall...   \n",
      "6     7  23503989  Oceans and Human Health (OHH): a European pers...   \n",
      "7     8  26286804  COST action TD1407: network on technology-crit...   \n",
      "8     9  29359236                  Role of Plastics on Human Health.   \n",
      "9    10  25023995  Syria: health in a country undergoing tragic t...   \n",
      "\n",
      "      score  tfidf_score  w2v_score  \n",
      "0  0.978366     1.000000   0.945916  \n",
      "1  0.692247     0.565997   0.881622  \n",
      "2  0.686508     0.477514   1.000000  \n",
      "3  0.604358     0.394402   0.919291  \n",
      "4  0.574311     0.312433   0.967128  \n",
      "5  0.573550     0.330185   0.938597  \n",
      "6  0.563862     0.297147   0.963934  \n",
      "7  0.547908     0.298507   0.922008  \n",
      "8  0.546071     0.247384   0.994103  \n",
      "9  0.539753     0.263152   0.954656  \n"
     ]
    }
   ],
   "source": [
    "# Cell 8 - Test interactif\n",
    "\n",
    "# Exemple query : utilise abstract d'un document\n",
    "test_pmid = corpus_df.iloc[0]['pmid']\n",
    "test_query = corpus_df.iloc[0]['abstract'][:200]  # 200 premiers chars\n",
    "\n",
    "print(f\"Query test (PMID {test_pmid}) :\")\n",
    "print(test_query)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "results = retriever.retrieve(test_query, top_k=10, return_scores=True)\n",
    "print(results[['rank', 'pmid', 'title', 'score', 'tfidf_score', 'w2v_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âvaluation compl√®te\n",
    "\n",
    "Cette cellule lance une **√©valuation automatique** du retriever avec le gold standard. Elle charge le mapping `query ‚Üí documents pertinents`, d√©finit une fonction qui calcule des m√©triques classiques (P@10, AP/MAP, NDCG@10, Recall@10), puis teste le syst√®me sur un sous-√©chantillon de requ√™tes. Pour chaque requ√™te, elle prend l‚Äôabstract comme texte de recherche, r√©cup√®re les 100 meilleurs documents, compare aux documents pertinents attendus, stocke les scores, affiche les moyennes globales et sauvegarde le tout dans un CSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√âvaluation sur 100 queries...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:30<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "R√âSULTATS GLOBAUX\n",
      "================================================================================\n",
      "MAP       : 0.5430\n",
      "NDCG@10   : 0.6064\n",
      "P@10      : 0.6859\n",
      "Recall@10 : 0.1752\n",
      "\n",
      "‚úì R√©sultats sauvegard√©s dans results\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Chargement query mapping\n",
    "with open(DATA_DIR / \"processed/query_relevant.pkl\", 'rb') as f:\n",
    "    query_relevant = pickle.load(f)\n",
    "\n",
    "def calculate_metrics(retrieved_pmids, relevant_pmids, k=10):\n",
    "    \"\"\"Calcul P@K, AP, NDCG@K\"\"\"\n",
    "    retrieved_k = retrieved_pmids[:k]\n",
    "    relevant_set = set(relevant_pmids)\n",
    "    \n",
    "    # Precision@K\n",
    "    p_at_k = len(set(retrieved_k) & relevant_set) / k if k > 0 else 0\n",
    "    \n",
    "    # Average Precision\n",
    "    ap = 0\n",
    "    num_relevant = 0\n",
    "    for i, pmid in enumerate(retrieved_pmids, 1):\n",
    "        if pmid in relevant_set:\n",
    "            num_relevant += 1\n",
    "            ap += num_relevant / i\n",
    "    ap = ap / len(relevant_pmids) if relevant_pmids else 0\n",
    "    \n",
    "    # NDCG@K\n",
    "    dcg = sum([1 / np.log2(i + 2) for i, pmid in enumerate(retrieved_k) \n",
    "               if pmid in relevant_set])\n",
    "    idcg = sum([1 / np.log2(i + 2) for i in range(min(len(relevant_pmids), k))])\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    # Recall@K\n",
    "    recall = len(set(retrieved_k) & relevant_set) / len(relevant_pmids) if relevant_pmids else 0\n",
    "    \n",
    "    return {\"P@10\": p_at_k, \"AP\": ap, \"NDCG@10\": ndcg, \"Recall@10\": recall}\n",
    "\n",
    "# Sous-√©chantillon queries (100 pour test rapide, puis augmenter)\n",
    "sample_size = 100\n",
    "sample_queries = list(query_relevant.keys())[:sample_size]\n",
    "\n",
    "print(f\"√âvaluation sur {len(sample_queries)} queries...\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for query_pmid in tqdm(sample_queries):\n",
    "    # R√©cup√©ration document query\n",
    "    query_doc = corpus_df[corpus_df['pmid'] == query_pmid]\n",
    "    if query_doc.empty:\n",
    "        continue\n",
    "    \n",
    "    query_text = query_doc.iloc[0]['abstract']\n",
    "    \n",
    "    # Retrieval\n",
    "    try:\n",
    "        retrieved = retriever.retrieve(query_text, top_k=100)\n",
    "        retrieved_pmids = retrieved['pmid'].tolist()\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Ground truth\n",
    "    relevant_pmids = [d['pmid'] for d in query_relevant[query_pmid]['relevant']]\n",
    "    \n",
    "    if not relevant_pmids:\n",
    "        continue\n",
    "    \n",
    "    # M√©triques\n",
    "    metrics = calculate_metrics(retrieved_pmids, relevant_pmids, k=10)\n",
    "    metrics['query_pmid'] = query_pmid\n",
    "    metrics['n_relevant'] = len(relevant_pmids)\n",
    "    \n",
    "    all_results.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(all_results)\n",
    "\n",
    "# R√©sultats globaux\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"R√âSULTATS GLOBAUX\")\n",
    "print(\"=\"*80)\n",
    "print(f\"MAP       : {results_df['AP'].mean():.4f}\")\n",
    "print(f\"NDCG@10   : {results_df['NDCG@10'].mean():.4f}\")\n",
    "print(f\"P@10      : {results_df['P@10'].mean():.4f}\")\n",
    "print(f\"Recall@10 : {results_df['Recall@10'].mean():.4f}\")\n",
    "\n",
    "# Sauvegarde\n",
    "results_df.to_csv(RESULTS_DIR / f\"evaluation_{sample_size}queries.csv\", index=False)\n",
    "print(f\"\\n‚úì R√©sultats sauvegard√©s dans {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface chatbot interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ü§ñ SCIENTIFIC LITERATURE EXPLORER - Interactive Search\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218012351d27438e98f9a5959d22a936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h4>Example Queries (click to use):</h4>'), HBox(children=(Button(description='Brea‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Widgets interface\n",
    "query_input = widgets.Textarea(\n",
    "    placeholder='Enter your search query or paste an abstract...',\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='90%', height='100px')\n",
    ")\n",
    "\n",
    "top_k_slider = widgets.IntSlider(\n",
    "    value=10, \n",
    "    min=5, \n",
    "    max=50, \n",
    "    step=5,\n",
    "    description='Top-K:',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "alpha_slider = widgets.FloatSlider(\n",
    "    value=0.6,\n",
    "    min=0.0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Œ± (TF-IDF):',\n",
    "    layout=widgets.Layout(width='300px')\n",
    ")\n",
    "\n",
    "search_button = widgets.Button(\n",
    "    description='üîç Search',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "clear_button = widgets.Button(\n",
    "    description='Clear',\n",
    "    button_style='',\n",
    "    layout=widgets.Layout(width='150px', height='40px')\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Exemples queries\n",
    "example_queries = {\n",
    "    \"Breast cancer immunotherapy\": \"immunotherapy checkpoint inhibitors PD-1 PD-L1 breast cancer treatment response\",\n",
    "    \"EGFR mutations lung cancer\": \"epidermal growth factor receptor EGFR mutation lung cancer targeted therapy\",\n",
    "    \"Melanoma BRAF inhibitors\": \"melanoma BRAF V600E mutation targeted therapy vemurafenib dabrafenib\",\n",
    "    \"Colorectal cancer biomarkers\": \"colorectal cancer biomarkers KRAS mutation microsatellite instability prognosis\"\n",
    "}\n",
    "\n",
    "example_buttons = [widgets.Button(description=name, layout=widgets.Layout(width='200px')) \n",
    "                   for name in example_queries.keys()]\n",
    "\n",
    "def on_search(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        \n",
    "        query = query_input.value.strip()\n",
    "        k = top_k_slider.value\n",
    "        alpha = alpha_slider.value\n",
    "        beta = 1.0 - alpha\n",
    "        \n",
    "        if not query:\n",
    "            print(\"‚ö†Ô∏è Enter a query\")\n",
    "            return\n",
    "        \n",
    "        print(f\"üîç Searching for: {query[:100]}...\")\n",
    "        print(f\"Parameters: Top-{k}, Œ±={alpha:.1f} (TF-IDF), Œ≤={beta:.1f} (Word2Vec)\\n\")\n",
    "        \n",
    "        # Update retriever weights\n",
    "        retriever.alpha = alpha\n",
    "        retriever.beta = beta\n",
    "        \n",
    "        try:\n",
    "            results = retriever.retrieve(query, top_k=k, return_scores=True)\n",
    "            \n",
    "            # Affichage HTML format√©\n",
    "            html = f\"\"\"\n",
    "            <style>\n",
    "                .result-card {{\n",
    "                    margin-bottom: 20px;\n",
    "                    padding: 15px;\n",
    "                    border-left: 4px solid #007acc;\n",
    "                    background-color: #f8f9fa;\n",
    "                    border-radius: 4px;\n",
    "                }}\n",
    "                .result-rank {{\n",
    "                    font-weight: bold;\n",
    "                    color: #007acc;\n",
    "                    font-size: 18px;\n",
    "                }}\n",
    "                .result-title {{\n",
    "                    font-size: 16px;\n",
    "                    color: #333;\n",
    "                    margin: 8px 0;\n",
    "                    font-weight: 500;\n",
    "                }}\n",
    "                .result-meta {{\n",
    "                    font-size: 12px;\n",
    "                    color: #666;\n",
    "                    margin-top: 8px;\n",
    "                }}\n",
    "                .score-bar {{\n",
    "                    display: inline-block;\n",
    "                    height: 10px;\n",
    "                    background-color: #007acc;\n",
    "                    margin-left: 5px;\n",
    "                    vertical-align: middle;\n",
    "                }}\n",
    "            </style>\n",
    "            <h3>üìÑ Top {len(results)} Results</h3>\n",
    "            \"\"\"\n",
    "            \n",
    "            for _, row in results.iterrows():\n",
    "                score_width = int(row['score'] * 200)\n",
    "                tfidf_width = int(row['tfidf_score'] * 100)\n",
    "                w2v_width = int(row['w2v_score'] * 100)\n",
    "                \n",
    "                html += f\"\"\"\n",
    "                <div class='result-card'>\n",
    "                    <span class='result-rank'>#{row['rank']}</span>\n",
    "                    <div class='result-title'>{row['title']}</div>\n",
    "                    <div class='result-meta'>\n",
    "                        PMID: {row['pmid']} | \n",
    "                        Combined: {row['score']:.3f} <span class='score-bar' style='width:{score_width}px;'></span><br>\n",
    "                        TF-IDF: {row['tfidf_score']:.3f} <span class='score-bar' style='width:{tfidf_width}px; background-color:#28a745;'></span> | \n",
    "                        Word2Vec: {row['w2v_score']:.3f} <span class='score-bar' style='width:{w2v_width}px; background-color:#ffc107;'></span>\n",
    "                    </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            \n",
    "            display(HTML(html))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "\n",
    "def on_clear(b):\n",
    "    query_input.value = \"\"\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "\n",
    "def on_example_click(button):\n",
    "    query_input.value = example_queries[button.description]\n",
    "\n",
    "# Connexions √©v√©nements\n",
    "search_button.on_click(on_search)\n",
    "clear_button.on_click(on_clear)\n",
    "for btn in example_buttons:\n",
    "    btn.on_click(on_example_click)\n",
    "\n",
    "# Layout interface\n",
    "print(\"=\"*80)\n",
    "print(\" SCIENTIFIC LITERATURE EXPLORER - Interactive Search\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h4>Example Queries (click to use):</h4>\"),\n",
    "    widgets.HBox(example_buttons[:2]),\n",
    "    widgets.HBox(example_buttons[2:]),\n",
    "    widgets.HTML(\"<br><h4>Custom Query:</h4>\"),\n",
    "    query_input,\n",
    "    widgets.HTML(\"<br><h4>Search Parameters:</h4>\"),\n",
    "    widgets.HBox([top_k_slider, alpha_slider]),\n",
    "    widgets.HTML(\"<br>\"),\n",
    "    widgets.HBox([search_button, clear_button]),\n",
    "    widgets.HTML(\"<br>\"),\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: NORMAL_CASES\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'breast cancer treatment outcomes'\n",
      "Expected: Standard biomedical\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8943 | Max Score: 0.9835\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.984] Nanomedicine applications in the treatment of breast cancer: current s...\n",
      "  2. [0.924] Patient Navigation in Breast Cancer Treatment and Survivorship: A Syst...\n",
      "  3. [0.896] Breast cancer in the personal genomics era....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'EGFR mutation lung cancer prognosis'\n",
      "Expected: With biomarker\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9434 | Max Score: 0.9962\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.996] Epidermal growth factor receptor gene amplification and gefitinib sens...\n",
      "  2. [0.954] Development of personalized treatments in lung cancer: focusing on the...\n",
      "  3. [0.927] Non-classic EGFR mutations in a cohort of Dutch EGFR-mutated NSCLC pat...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'pembrolizumab immunotherapy melanoma response'\n",
      "Expected: Treatment specific\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8047 | Max Score: 0.9491\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.949] A Rare Thyroid Metastasis from Uveal Melanoma and Response to Immunoth...\n",
      "  2. [0.810] Glucocorticoids did not reverse type 1 diabetes mellitus secondary to ...\n",
      "  3. [0.789] Safety of immune checkpoint inhibitors in Chinese patients with melano...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'colorectal cancer microsatellite instability chemotherapy resistance'\n",
      "Expected: Multi-concept\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8483 | Max Score: 0.9956\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.996] Role of microsatellite instability in the management of colorectal can...\n",
      "  2. [0.844] Distinctive patterns of p53 protein expression and microsatellite inst...\n",
      "  3. [0.808] Clinical significance of microsatellite instability in colorectal canc...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: AMBIGUOUS_TERMS\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'cold'\n",
      "Expected: Polysemy 1\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8998 | Max Score: 0.9954\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.995] Proteomic Analysis of Rice Seedlings Under Cold Stress....\n",
      "  2. [0.889] Water restriction and fluid temperature alter preference for water and...\n",
      "  3. [0.885] Engineering cold stress tolerance in crop plants....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'culture'\n",
      "Expected: Polysemy 2\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9072 | Max Score: 0.9567\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.957] A modified cornish pasty method for ex ovo culture of the chick embryo...\n",
      "  2. [0.933] Microfluidic perfusion culture....\n",
      "  3. [0.891] Determination of lignans, phenolic acids and antioxidant capacity in t...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'positive'\n",
      "Expected: Polysemy 3\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8852 | Max Score: 0.9049\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.905] Dengue in patients with central nervous system manifestations, Brazil....\n",
      "  2. [0.901] The roles of affect dysregulation and positive affect in non-suicidal ...\n",
      "  3. [0.884] Longitudinal Relations Among Positivity, Perceived Positive School Cli...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'AML'\n",
      "Expected: Acronym confusion\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9542 | Max Score: 0.9903\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.990] AML with translocation t(8;16)(p11;p13) demonstrates unique cytomorpho...\n",
      "  2. [0.983] A patient with extramedullary acute myeloid leukaemia involving the br...\n",
      "  3. [0.972] Novel Therapeutics in Acute Myeloid Leukemia....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: OUT_OF_DOMAIN\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'quantum entanglement particle physics'\n",
      "Expected: Physics\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9107 | Max Score: 0.9635\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.964] Heralded quantum steering over a high-loss channel....\n",
      "  2. [0.911] Quantum metrology. Fisher information and entanglement of non-Gaussian...\n",
      "  3. [0.894] Efficient entanglement distillation without quantum memory....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'neural network backpropagation algorithm'\n",
      "Expected: Computer science\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9325 | Max Score: 1.0000\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [1.000] High Performance Implementation of 3D Convolutional Neural Networks on...\n",
      "  2. [0.954] Big Data: A Parallel Particle Swarm Optimization-Back-Propagation Neur...\n",
      "  3. [0.933] Global stability of complex-valued recurrent neural networks with time...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'French revolution Napoleon Bonaparte'\n",
      "Expected: History\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8414 | Max Score: 1.0000\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [1.000] The Darwinian revolution: rethinking its meaning and significance....\n",
      "  2. [0.853] On Darwin's science and its contexts....\n",
      "  3. [0.837] What is French for d√©j√† vu? Descriptions of d√©j√† vu in native French a...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'chocolate cake recipe baking temperature'\n",
      "Expected: Cooking\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8663 | Max Score: 1.0000\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [1.000] Physicochemical and functional properties of protein concentrate from ...\n",
      "  2. [0.864] Experimental assessment of toxic phytochemicals in Jatropha curcas: oi...\n",
      "  3. [0.864] Experimental effects of chocolate deprivation on cravings, mood, and c...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: NONSENSE\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'purple elephant dancing quantum spaghetti'\n",
      "Expected: Random words\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8829 | Max Score: 0.9226\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.923] Vocal communication in African elephants (Loxodonta africana)....\n",
      "  2. [0.899] Palaeogenomes of Eurasian straight-tusked elephants challenge the curr...\n",
      "  3. [0.868] Relatedness and demography of African forest elephants: inferences fro...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'xkjhfds qwerty asdfgh zxcvbn'\n",
      "Expected: Gibberish\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: '123 456 789'\n",
      "Expected: Numbers only\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: '@@@ ### $$$ %%% &&&'\n",
      "Expected: Special chars\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: TOO_SPECIFIC\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'BRAF V600E mutation codon 600 valine glutamic acid substitution vemurafenib resistance mechanism ATP binding pocket conformational change'\n",
      "Expected: Hyper-specific 1\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8789 | Max Score: 0.9357\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.936] Vemurafenib....\n",
      "  2. [0.875] Hsp90: Friends, clients and natural foes....\n",
      "  3. [0.872] Reactivation of mitogen-activated protein kinase (MAPK) pathway by FGF...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'hereditary angioedema C1 esterase inhibitor deficiency bradykinin'\n",
      "Expected: Rare condition\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8984 | Max Score: 0.9519\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.952] Converting an esterase into an epoxide hydrolase....\n",
      "  2. [0.927] SGNH hydrolase-type esterase domain containing Cbes-AcXE2: a novel and...\n",
      "  3. [0.893] Functional and structural characterization of a thermostable acetyl es...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'LMNA R482W mutation progeria syndrome'\n",
      "Expected: Ultra-rare gene\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9545 | Max Score: 0.9780\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.978] Alstr√∂m syndrome: insights into the pathogenesis of metabolic disorder...\n",
      "  2. [0.961] TINF2, a component of the shelterin telomere protection complex, is mu...\n",
      "  3. [0.951] Novel compound heterozygous mutations in BCS1L gene causing Bjornstad ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'CheckMate 067 nivolumab ipilimumab combination melanoma phase III results'\n",
      "Expected: Specific trial\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9145 | Max Score: 1.0000\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [1.000] Efficacy and toxicity of treatment with the anti-CTLA-4 antibody ipili...\n",
      "  2. [0.952] Efficacy and safety of anti-PD-1 and anti-PD-1 combined with anti-CTLA...\n",
      "  3. [0.914] CTLA-4 blockade: therapeutic potential in cancer treatments....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: TOO_GENERAL\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'cancer'\n",
      "Expected: Single word\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8713 | Max Score: 0.9065\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.907] What is a cancer cell? Why does it metastasize?...\n",
      "  2. [0.889] [LncRNA in prostate cancer: an update]....\n",
      "  3. [0.869] A-to-I RNA Editing: An Overlooked Source of Cancer Mutations....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'treatment'\n",
      "Expected: Vague\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8143 | Max Score: 0.9098\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.910] Majocchi's granuloma - case report....\n",
      "  2. [0.801] Treatment of metastatic melanoma with electrochemotherapy....\n",
      "  3. [0.796] Guidelines for the treatment of growth hormone excess and growth hormo...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'patient outcome study results'\n",
      "Expected: Generic\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8503 | Max Score: 0.9316\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.932] The chronic care model and diabetes management in US primary care sett...\n",
      "  2. [0.875] Medication adherence to oral anticancer drugs: systematic review....\n",
      "  3. [0.829] Recommendations for improving the quality of reporting clinical electr...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'medical research health disease'\n",
      "Expected: Empty semantic\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8746 | Max Score: 0.9723\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.972] Global informetric perspective studies on translational medical resear...\n",
      "  2. [0.895] [Medical research-ethics applied to social sciences: relevance, limits...\n",
      "  3. [0.890] Willingness to participate in health research: Tunisian survey....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: CONTRADICTORY\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'breast cancer prostate cancer'\n",
      "Expected: Opposite terms\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9148 | Max Score: 0.9562\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.956] [LncRNA in prostate cancer: an update]....\n",
      "  2. [0.934] Cellular identity crisis: Antiandrogen resistance by lineage plasticit...\n",
      "  3. [0.922] Inhibition of Stat5a/b Enhances Proteasomal Degradation of Androgen Re...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'pediatric elderly geriatric neonatal'\n",
      "Expected: Conflicting age\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9276 | Max Score: 0.9698\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.970] Geriatric consultation service in emergency department: how does it wo...\n",
      "  2. [0.961] Geriatric consultation services-are wards more effective than teams?...\n",
      "  3. [0.919] Single incision laparoscopic cholecystectomy in geriatric patients....\n",
      "\n",
      "üí° Result diversity: Low (clustered)\n",
      "\n",
      "================================================================================\n",
      "Query: 'survival mortality improvement deterioration'\n",
      "Expected: Mixed outcomes\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8409 | Max Score: 0.8899\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.890] Application of calcifying bacteria for remediation of stones and cultu...\n",
      "  2. [0.883] The changing fates of the world's mammals....\n",
      "  3. [0.849] Importance of respiratory rate for the prediction of clinical deterior...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: TYPOS\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'brest canser treatmant'\n",
      "Expected: Misspelling 1\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'melanomma immunotherappy'\n",
      "Expected: Misspelling 2\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'ERFG mutaiton lugn cancre'\n",
      "Expected: Transposition\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.0000 | Max Score: 0.0000\n",
      "‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.000] Potentially harmful elements (PHEs) in scalp hair, soil and metallurgi...\n",
      "  2. [0.000] The relationship of renal function to segmental vascular stiffness, an...\n",
      "  3. [0.000] Performance analysis of elite men's and women's wheelchair basketball ...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "\n",
      "################################################################################\n",
      "# CATEGORY: SYNONYMS_TEST\n",
      "################################################################################\n",
      "\n",
      "================================================================================\n",
      "Query: 'myocardial infarction heart attack'\n",
      "Expected: Medical synonyms\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8724 | Max Score: 0.9570\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.957] Macrophage Polarization as a Therapeutic Target in Myocardial Infarcti...\n",
      "  2. [0.886] Galectin-3 and post-myocardial infarction cardiac remodeling....\n",
      "  3. [0.869] Acute coronary syndrome....\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'acetaminophen paracetamol tylenol'\n",
      "Expected: Drug names\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.9053 | Max Score: 0.9941\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.994] Acetaminophen for patent ductus arteriosus....\n",
      "  2. [0.887] Oral paracetamol in treatment of closure of patent ductus arteriosus i...\n",
      "  3. [0.882] Early paracetamol treatment associated with lowered risk of persistent...\n",
      "\n",
      "üí° Result diversity: High\n",
      "\n",
      "================================================================================\n",
      "Query: 'colon large intestine bowel'\n",
      "Expected: Anatomy\n",
      "--------------------------------------------------------------------------------\n",
      "üìä Avg Score: 0.8254 | Max Score: 0.8761\n",
      "‚úì‚úì GOOD SCORES - Strong matches\n",
      "\n",
      "Top 3 results:\n",
      "  1. [0.876] Melanosis coli in patients with colon cancer....\n",
      "  2. [0.828] [First part: the intestinal microbiota]....\n",
      "  3. [0.823] Spatial heterogeneity of gut microbiota reveals multiple bacterial com...\n",
      "\n",
      "üí° Result diversity: High\n"
     ]
    }
   ],
   "source": [
    "test_cases = {\n",
    "    \"NORMAL_CASES\": {\n",
    "        \"Standard biomedical\": \"breast cancer treatment outcomes\",\n",
    "        \"With biomarker\": \"EGFR mutation lung cancer prognosis\",\n",
    "        \"Treatment specific\": \"pembrolizumab immunotherapy melanoma response\",\n",
    "        \"Multi-concept\": \"colorectal cancer microsatellite instability chemotherapy resistance\"\n",
    "    },\n",
    "    \n",
    "    \"AMBIGUOUS_TERMS\": {\n",
    "        \"Polysemy 1\": \"cold\",  # Maladie vs temp√©rature\n",
    "        \"Polysemy 2\": \"culture\",  # Culture cellulaire vs culture sociale\n",
    "        \"Polysemy 3\": \"positive\",  # Test positif vs affect positif\n",
    "        \"Acronym confusion\": \"AML\"  # Acute Myeloid Leukemia vs autres AML\n",
    "    },\n",
    "    \n",
    "    \"OUT_OF_DOMAIN\": {\n",
    "        \"Physics\": \"quantum entanglement particle physics\",\n",
    "        \"Computer science\": \"neural network backpropagation algorithm\",\n",
    "        \"History\": \"French revolution Napoleon Bonaparte\",\n",
    "        \"Cooking\": \"chocolate cake recipe baking temperature\"\n",
    "    },\n",
    "    \n",
    "    \"NONSENSE\": {\n",
    "        \"Random words\": \"purple elephant dancing quantum spaghetti\",\n",
    "        \"Gibberish\": \"xkjhfds qwerty asdfgh zxcvbn\",\n",
    "        \"Numbers only\": \"123 456 789\",\n",
    "        \"Special chars\": \"@@@ ### $$$ %%% &&&\"\n",
    "    },\n",
    "    \n",
    "    \"TOO_SPECIFIC\": {\n",
    "        \"Hyper-specific 1\": \"BRAF V600E mutation codon 600 valine glutamic acid substitution vemurafenib resistance mechanism ATP binding pocket conformational change\",\n",
    "        \"Rare condition\": \"hereditary angioedema C1 esterase inhibitor deficiency bradykinin\",\n",
    "        \"Ultra-rare gene\": \"LMNA R482W mutation progeria syndrome\",\n",
    "        \"Specific trial\": \"CheckMate 067 nivolumab ipilimumab combination melanoma phase III results\"\n",
    "    },\n",
    "    \n",
    "    \"TOO_GENERAL\": {\n",
    "        \"Single word\": \"cancer\",\n",
    "        \"Vague\": \"treatment\",\n",
    "        \"Generic\": \"patient outcome study results\",\n",
    "        \"Empty semantic\": \"medical research health disease\"\n",
    "    },\n",
    "    \n",
    "    \"CONTRADICTORY\": {\n",
    "        \"Opposite terms\": \"breast cancer prostate cancer\",\n",
    "        \"Conflicting age\": \"pediatric elderly geriatric neonatal\",\n",
    "        \"Mixed outcomes\": \"survival mortality improvement deterioration\"\n",
    "    },\n",
    "    \n",
    "    \"TYPOS\": {\n",
    "        \"Misspelling 1\": \"brest canser treatmant\",\n",
    "        \"Misspelling 2\": \"melanomma immunotherappy\",\n",
    "        \"Transposition\": \"ERFG mutaiton lugn cancre\"\n",
    "    },\n",
    "    \n",
    "    \"SYNONYMS_TEST\": {\n",
    "        \"Medical synonyms\": \"myocardial infarction heart attack\",\n",
    "        \"Drug names\": \"acetaminophen paracetamol tylenol\",\n",
    "        \"Anatomy\": \"colon large intestine bowel\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Fonction test avec analyse\n",
    "def test_query_detailed(query, expected_behavior=\"\"):\n",
    "    \"\"\"Test query avec analyse r√©sultats\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    if expected_behavior:\n",
    "        print(f\"Expected: {expected_behavior}\")\n",
    "    print('-'*80)\n",
    "    \n",
    "    try:\n",
    "        results = retriever.retrieve(query, top_k=5, return_scores=True)\n",
    "        \n",
    "        if len(results) == 0:\n",
    "            print(\"  NO RESULTS\")\n",
    "            return\n",
    "        \n",
    "        avg_score = results['score'].mean()\n",
    "        max_score = results['score'].max()\n",
    "        \n",
    "        print(f\" Avg Score: {avg_score:.4f} | Max Score: {max_score:.4f}\")\n",
    "        \n",
    "        if max_score < 0.05:\n",
    "            print(\"‚ö†Ô∏è VERY LOW SCORES - Likely irrelevant\")\n",
    "        elif max_score < 0.15:\n",
    "            print(\"‚ö†Ô∏è LOW SCORES - Weak matches\")\n",
    "        elif max_score < 0.30:\n",
    "            print(\"‚úì MODERATE SCORES - Acceptable matches\")\n",
    "        else:\n",
    "            print(\"‚úì‚úì GOOD SCORES - Strong matches\")\n",
    "        \n",
    "        print(\"\\nTop 3 results:\")\n",
    "        for _, row in results.head(3).iterrows():\n",
    "            print(f\"  {row['rank']}. [{row['score']:.3f}] {row['title'][:70]}...\")\n",
    "        \n",
    "        # Analyse diversit√© r√©sultats\n",
    "        if len(results) >= 5:\n",
    "            top5_titles = results.head(5)['title'].tolist()\n",
    "            # Check si titres tr√®s similaires (signe de bon clustering)\n",
    "            print(f\"\\n  Result diversity: {'High' if len(set([t[:30] for t in top5_titles])) == 5 else 'Low (clustered)'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ERROR: {e}\")\n",
    "\n",
    "# Ex√©cution tests par cat√©gorie\n",
    "for category, queries in test_cases.items():\n",
    "    print(f\"\\n\\n{'#'*80}\")\n",
    "    print(f\"# CATEGORY: {category}\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    for name, query in queries.items():\n",
    "        test_query_detailed(query, expected_behavior=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datacamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
